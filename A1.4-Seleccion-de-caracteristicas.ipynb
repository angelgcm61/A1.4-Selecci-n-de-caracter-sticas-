{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "10753e06-0b00-4844-87a4-8c65669a71ca",
   "metadata": {},
   "source": [
    "Cargamos el árchivo A1.4-Vino-Tinto.csv con la librería de pandas e imprimimos la dimensión de este como los primeros 5 filas de cada columna."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "e6be2f4b-8e78-4502-8ca9-ac2228f87dac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensiones: (1599, 12)\n",
      "   acidezFija  acidezVolatil  acidoCitrico  azucarResidual  cloruros  \\\n",
      "0         7.4           0.70          0.00             1.9     0.076   \n",
      "1         7.8           0.88          0.00             2.6     0.098   \n",
      "2         7.8           0.76          0.04             2.3     0.092   \n",
      "3        11.2           0.28          0.56             1.9     0.075   \n",
      "4         7.4           0.70          0.00             1.9     0.076   \n",
      "\n",
      "   dioxidoAzufreLibre  dioxidoAzufreTotal  densidad    pH  sulfatos  alcohol  \\\n",
      "0                11.0                34.0    0.9978  3.51      0.56      9.4   \n",
      "1                25.0                67.0    0.9968  3.20      0.68      9.8   \n",
      "2                15.0                54.0    0.9970  3.26      0.65      9.8   \n",
      "3                17.0                60.0    0.9980  3.16      0.58      9.8   \n",
      "4                11.0                34.0    0.9978  3.51      0.56      9.4   \n",
      "\n",
      "   calidad  \n",
      "0        5  \n",
      "1        5  \n",
      "2        5  \n",
      "3        6  \n",
      "4        5  \n"
     ]
    }
   ],
   "source": [
    "import pandas as ps\n",
    "datos=ps.read_csv(\"A1.4-Vino-Tinto.csv\")\n",
    "print(\"Dimensiones:\", datos.shape)\n",
    "print(datos.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e038764f-b7d9-4269-9e7d-f8f23a0ea8c9",
   "metadata": {},
   "source": [
    "Aplicamos la función train_test_split de la librería sklearn.model_selection y quitamos la variable de calidad para x y en y la llamamos. A su vez ahora dividiremos con la función del inicio en 4 partes, siendo para X train y test al igual que para y train y test, dividiendolos en 80/20 e imprimimos cada dimensión de el entrenamiento y pruebas, corroborando que sea la misma dimensión de todo el archivo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "9d722e4a-8235-4b49-a769-9c3e72b3e555",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenamiento: (1279, 12)\n",
      "Pruebas: (320, 12)\n",
      "      acidezFija  acidezVolatil  acidoCitrico  azucarResidual  cloruros  \\\n",
      "911          9.1           0.28          0.46             9.0     0.114   \n",
      "8            7.8           0.58          0.02             2.0     0.073   \n",
      "790          7.4           0.37          0.43             2.6     0.082   \n",
      "885          8.9           0.75          0.14             2.5     0.086   \n",
      "1324         6.7           0.46          0.24             1.7     0.077   \n",
      "2            7.8           0.76          0.04             2.3     0.092   \n",
      "725          9.0           0.66          0.17             3.0     0.077   \n",
      "365         10.0           0.42          0.50             3.4     0.107   \n",
      "807          8.2           0.28          0.40             2.4     0.052   \n",
      "17           8.1           0.56          0.28             1.7     0.368   \n",
      "\n",
      "      dioxidoAzufreLibre  dioxidoAzufreTotal  densidad    pH  sulfatos  \\\n",
      "911                  3.0                 9.0   0.99901  3.18      0.60   \n",
      "8                    9.0                18.0   0.99680  3.36      0.57   \n",
      "790                 18.0                82.0   0.99708  3.33      0.68   \n",
      "885                  9.0                30.0   0.99824  3.34      0.64   \n",
      "1324                18.0                34.0   0.99480  3.39      0.60   \n",
      "2                   15.0                54.0   0.99700  3.26      0.65   \n",
      "725                  5.0                13.0   0.99760  3.29      0.55   \n",
      "365                  7.0                21.0   0.99790  3.26      0.93   \n",
      "807                  4.0                10.0   0.99356  3.33      0.70   \n",
      "17                  16.0                56.0   0.99680  3.11      1.28   \n",
      "\n",
      "      alcohol  calidad  \n",
      "911      10.9        6  \n",
      "8         9.5        7  \n",
      "790       9.7        6  \n",
      "885      10.5        5  \n",
      "1324     10.6        6  \n",
      "2         9.8        5  \n",
      "725      10.4        5  \n",
      "365      11.8        6  \n",
      "807      12.8        7  \n",
      "17        9.3        5  \n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = train.drop('calidad', axis=1)\n",
    "y= train.calidad\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size = 0.8)\n",
    "\n",
    "print(\"Entrenamiento:\", train.shape)\n",
    "print(\"Pruebas:\",test.shape)\n",
    "print(train.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "babe6ff4-4e65-4d09-b6b4-10387a75d0fa",
   "metadata": {},
   "source": [
    "Generamos la función SequentialFeatureSelector de la librería mlxtend.feature_selection abreviandolo a SFS y a su vez también importamos la función LinearRegression de la librería sklearn.linear_model  para poder ejecutar de manera correcta la metodología de selección hacia adelante.\n",
    "\n",
    "Al linearRegression() le llamamos estimator para hacerlo mas visibles, a su vez ponemos los siguientes códigos para que funcione de la manera adecuada para estos datos:\n",
    "- k_features de 2,8 para seleccionar la cantidad de columnas\n",
    "- Forward true para que vaya hacia adelante \n",
    "- Scoring en 'r2' para que nos proporciones el R² de la aproximación lineal para saber que tan buena es\n",
    "- Cv=10 para asi realizar validación cruzada, y cuántas instancias de la misma.\n",
    "\n",
    "A su vez convertimos a este modelo a un fit de X_train y y_train y lo imprimimos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "031beec6-f9c4-4639-a4d1-7895e133f937",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variables seleccionadas:\n",
      " ('acidezVolatil', 'cloruros', 'dioxidoAzufreLibre', 'dioxidoAzufreTotal', 'pH', 'sulfatos', 'alcohol')\n"
     ]
    }
   ],
   "source": [
    "from mlxtend.feature_selection import SequentialFeatureSelector as SFS\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "estimator=LinearRegression()\n",
    "\n",
    "sfsForward=SFS(estimator,\n",
    "                  k_features=(2,8), \n",
    "                  forward=True,      \n",
    "                  scoring='r2',     \n",
    "                  cv=10)\n",
    "modeloF=sfsForward.fit(X_train, y_train)\n",
    "print(\"Variables seleccionadas:\\n\", modeloF.k_feature_names_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1085a2da-4de0-4519-ac81-b096559145ba",
   "metadata": {},
   "source": [
    "Generamos la función r2_score de la librería sklearn.metrics\n",
    "Primero convertiremos el ModeloF a una lista para poder agrupar los datos de manera correcto, despuéscategorizaremos el X para forward tanro en train y en test en base a la lista que creamos.\n",
    "Luego crearemos un modelos fit de la regresión lineal  y la y predicción para el forward usando el comando predictic. Para poder asi obtener el R² de forward con la funcion previamente llamada en conjunto del y test y forwards."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "753af5f9-8984-4668-8b94-5c7d3d4ce70d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R² del modelo Forward: 0.37047640740230625\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "sfs_variaF=list(modeloF.k_feature_names_)\n",
    "\n",
    "X_trainForward=X_train[sfs_variaF]\n",
    "X_testForward = X_test[sfs_variaF]\n",
    "\n",
    "linearR.fit(X_trainForward, y_train)\n",
    "y_predForward=linearR.predict(X_testForward)\n",
    "\n",
    "r2Forward=r2_score(y_test, y_predForward)\n",
    "print(\"R² del modelo Forward:\", r2Forward)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "621a197e-fa70-4866-9184-cf56f734425d",
   "metadata": {},
   "source": [
    "Volvemos a aplicar la secuencia que en el punto 3, pero ahora definiendo los  datos para un Backward, para esto cambiamos el forward a false y el k_features a 2,5 para tener menos variables de inicio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "82c2e1dc-e897-43b9-a2c7-ae095fc8693f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variables seleccionadas:\n",
      " ('acidezVolatil', 'cloruros', 'dioxidoAzufreTotal', 'sulfatos', 'alcohol')\n"
     ]
    }
   ],
   "source": [
    "sfsBackward=SFS(estimator,\n",
    "                  k_features=(2,5), \n",
    "                  forward=False,\n",
    "                  scoring='r2',     \n",
    "                  cv=10)\n",
    "modeloB=sfsBackward.fit(X_train, y_train)\n",
    "print(\"Variables seleccionadas:\\n\", modeloB.k_feature_names_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee249ddb-7c15-4554-b2a2-d0c197f49398",
   "metadata": {},
   "source": [
    "Repetiremos el proceso del punto 4 ahora con las variables del Backward y el puntos 5, a su vez imprimiendo una conclusión a estos dos diferentes procesos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "d3e6d28d-3ee1-4da2-83b4-3467188aed4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R² Backward: -0.010496017239536526\n",
      "Considero que el Forward fue mejor en este caso, puesto que tiene un R² mas grande, aunque tenga mas variables, lo cual\n",
      "podría significar que si la dejamos en 5 variables pueda tener mejor precisión que el modelo Backward\n"
     ]
    }
   ],
   "source": [
    "sfs_variaB=list(modeloB.k_feature_names_)\n",
    "\n",
    "X_trainBackward=X_train[sfs_variaB]\n",
    "X_testBackward=X_test[sfs_variaB]\n",
    "\n",
    "linearR.fit(X_trainBack, y_train)\n",
    "y_predBackward=linearR.predict(X_testBackward)\n",
    "\n",
    "r2Backward=r2_score(y_test, y_predBackward)\n",
    "print(\"R² Backward:\", r2Backward)\n",
    "\n",
    "print(\"Considero que el Forward fue mejor en este caso, puesto que tiene un R² mas grande, aunque tenga mas variables, lo cual\")\n",
    "print(\"podría significar que si la dejamos en 5 variables pueda tener mejor precisión que el modelo Backward\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
